{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch torchaudio bitsandbytes trl accelerate peft torchcodec datasets[audio] evaluate jiwer tensorboard"
      ],
      "metadata": {
        "id": "oNGCwQxAwI0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "AyTWC8W5bIPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    logging,\n",
        "    WhisperForConditionalGeneration,\n",
        "    WhisperProcessor,\n",
        "    WhisperFeatureExtractor,\n",
        "    WhisperTokenizer,\n",
        "    Seq2SeqTrainer,\n",
        "    Seq2SeqTrainingArguments,\n",
        ")\n",
        "from peft import LoraConfig, PeftModel\n",
        "from trl import SFTTrainer\n",
        "from evaluate import load\n"
      ],
      "metadata": {
        "id": "G70nBpVqwI27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = load_dataset(\"huuuyeah/meetingbank\", split=\"train\")\n",
        "eval_ds = load_dataset(\"huuuyeah/meetingbank\", split=\"validation\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "44548175e2b94ca3a30d6e9b93e6b8ec",
            "a006a9e02b984cb6a76f7b33eb5abb5e",
            "9de64a01de0342e79150064ba5263eaa",
            "c1c9c0033dbd4c739e31eb4f690b48b8",
            "7f8e044a55724a68af782951f68fdff7",
            "ae15d8d303d547b69656bab04fc945d5",
            "6edd5c9084174d329234d498a006c5cb",
            "17517d9eb39547fdb815a41581e45852",
            "c89082114e824b0ca9a26ada3de2866a",
            "6b57d7c750c0445ca3435a2efdaaf9f6",
            "846e2d849a03495b9357509a09934fa5",
            "3b89400e978c4a42a444a0936adae873",
            "97d62bd85c12478ca74cf2ac8fdd5d13",
            "4849d940a2804555861ada48fcb92148",
            "fba5c2f8c902447ea2464ec1e90a8fcc",
            "01c8e8ba14014c4cb2bb3a6d6cc2a0fe",
            "64b537b0ce44423e8e99d6608acaa126",
            "0f09467983e94bdfb22dd5397324d828",
            "80ce107219ac4bbbb91e362203434384",
            "59cea13687cd4faf86bad7764bc2508f",
            "de35e9f278a1438390f3b1a5a24e5a84",
            "5e58b7c7d6e54b73b4686a78e38b2930"
          ]
        },
        "id": "qOuXsYU_c_d_",
        "outputId": "aebe80e5-3492-4d4f-ac3a-c09d39a43f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/804 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44548175e2b94ca3a30d6e9b93e6b8ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/804 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b89400e978c4a42a444a0936adae873"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds"
      ],
      "metadata": {
        "id": "v2WzIjv04rwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f375e4-166d-450e-e98c-58cec54a523d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['summary', 'uid', 'id', 'transcript'],\n",
              "    num_rows: 100\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]['summary']"
      ],
      "metadata": {
        "id": "Uwb5td9f4r16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "7ce34f03-9c36-4a0c-850c-2f3af3b3ce9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AS AMENDED a bill for an ordinance amending the Denver Zoning Code to revise parking exemptions for pre-existing small zone lots. Approves a text amendment to the Denver Zoning Code to revise the Pre-Existing Small Zone Lot parking exemption. The Committee approved filing this bill at its meeting on 2-14-17. On 2-27-17, Council held this item in Committee to 3-20-17. Amended 3-20-17 to ensure that the parking exemption is applied for all uses. Some parking requirements are calculated based on gross floor area while others are on number of units and not explicitly for gross floor area, to further clarify the legislative intent of the proposed bill to emphasize the city’s commitment to more comprehensively address transportation demand management strategies in the short term, and to require a Zoning Permit with Informational Notice for all new buildings on Pre-Existing Small Zone Lots that request to use the small lot parking exemption; Enables all expansions to existing buildings to receive the full parking exemption; and clarifies at what point an “existing building” is considered '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
        "\n",
        "    batch[\"labels\"] = processor.tokenizer(batch[\"text\"]).input_ids\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "ysyM49xnphd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = train_ds.map(prepare_dataset)\n",
        "train_ds[0]"
      ],
      "metadata": {
        "id": "riRiu7za4r6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_ds = eval_ds.map(prepare_dataset)\n",
        "eval_ds[0]"
      ],
      "metadata": {
        "id": "yAlqS09h4r9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "meteor = evaluate.load(\"meteor\")\n",
        "def compute_metrics(pred):\n",
        "  pred_ids = pred.predictions\n",
        "  label_ids = pred.label_ids\n",
        "\n",
        "\n",
        "  results = {}\n",
        "\n",
        "  # ROUGE\n",
        "  rouge_result = rouge.compute(predictions=predictions, references=references)\n",
        "  results[\"ROUGE\"] = {k: round(v, 4) for k, v in rouge_result.items()}\n",
        "\n",
        "  # BERTScore\n",
        "  bert_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
        "  results[\"BERTScore\"] = {\n",
        "        \"precision\": round(bert_result[\"precision\"].mean().item(), 4),\n",
        "        \"recall\": round(bert_result[\"recall\"].mean().item(), 4),\n",
        "        \"f1\": round(bert_result[\"f1\"].mean().item(), 4)\n",
        "  }\n",
        "\n",
        "  # METEOR\n",
        "  meteor_result = meteor.compute(predictions=predictions, references=references)\n",
        "  results[\"METEOR\"] = {k: round(v, 4) for k, v in meteor_result.items()}\n",
        "\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "eqO7-Syi4r_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODEL NAMES\n",
        "model_name = \"google/gemma-3-4b-it\"\n",
        "ft_model = \"gemma-3-4b-it_ft\"\n",
        "\n",
        "#BITSANDBYTES PARAMTERS\n",
        "use_4bit = True\n",
        "quant_type = \"nf4\"\n",
        "bnb_compute_type = \"float16\"\n",
        "nest_quant = False\n",
        "\n",
        "\n",
        "#QLORA PARAMETERS\n",
        "rank = 64\n",
        "alpha = 16\n",
        "dropout = 0.1\n",
        "tgt_mod = [\"q_proj\", \"v_proj\"]\n",
        "bias = \"none\"\n",
        "task = \"CAUSAL_LM\"\n",
        "\n",
        "\n",
        "#TRAINING PARAMTERS\n",
        "output_dir = \"./gemma_qlora\"\n",
        "epochs = 1\n",
        "fp16 = False\n",
        "bf16 = False\n",
        "train_batch = 8\n",
        "eval_batch = 8\n",
        "grad_steps = 1\n",
        "max_grad_norm = 0.5\n",
        "lr = 2e-4\n",
        "weight_decay = 0.001\n",
        "warmup_ratio = 0.03\n",
        "optim = \"paged_adamw_32bit\"\n",
        "lr_schedule = \"cosine\"\n",
        "group_by_length = True\n",
        "save_steps = 0\n",
        "logging_steps = 2\n",
        "max_steps = 20\n",
        "report_to = \"tensorboard\"\n",
        "\n",
        "\n",
        "#SFT PARAMETERS\n",
        "device = {\"\": 0}\n",
        "max_len = None\n",
        "packing = False\n",
        "dataset_text_field = \"text\"\n"
      ],
      "metadata": {
        "id": "TmkGA7vZ4sDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "zu8fFcF54sFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_type = getattr(torch, bnb_compute_type)"
      ],
      "metadata": {
        "id": "r3v0w8nvNXW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit = use_4bit,\n",
        "    bnb_4bit_quant_type = quant_type,\n",
        "    bnb_4bit_compute_dtype = compute_type,\n",
        "    bnb_4bit_use_double_quant = nest_quant\n",
        ")"
      ],
      "metadata": {
        "id": "S7-NpFmlNXZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ],
      "metadata": {
        "id": "LgChk5G1NXb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_config = LoraConfig(\n",
        "    lora_alpha = alpha,\n",
        "    lora_dropout = dropout,\n",
        "    r = rank,\n",
        "    target_modules = tgt_mod,\n",
        "    bias = bias,\n",
        "    task_type = task\n",
        ")\n"
      ],
      "metadata": {
        "id": "ILp54sRo4sH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorSpeechSeq2SeqWithPadding:\n",
        "    processor: Any\n",
        "    decoder_start_token_id: int\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
        "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
        "\n",
        "        # Ensure input_features are float16 for compatibility with the quantized model\n",
        "        batch[\"input_features\"] = batch[\"input_features\"].to(torch.float16)\n",
        "\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
        "\n",
        "\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
        "            labels = labels[:, 1:]\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "id": "VKXgnIXDNo_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
        "    processor=processor,\n",
        "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
        ")\n"
      ],
      "metadata": {
        "id": "CFisOJMINpCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_arguments = TrainingArguments(\n",
        "    output_dir = output_dir,\n",
        "    num_train_epochs = epochs,\n",
        "    per_device_train_batch_size = train_batch,\n",
        "    per_device_eval_batch_size=eval_batch,\n",
        "    gradient_accumulation_steps = grad_steps,\n",
        "    predict_with_generate=True,\n",
        "    optim = optim,\n",
        "    save_steps = save_steps,\n",
        "    logging_steps = logging_steps,\n",
        "    learning_rate = lr,\n",
        "    weight_decay = weight_decay,\n",
        "    fp16 = fp16,\n",
        "    bf16 = bf16,\n",
        "    max_grad_norm = max_grad_norm,\n",
        "    max_steps = max_steps,\n",
        "    warmup_ratio = warmup_ratio,\n",
        "    group_by_length = group_by_length,\n",
        "    lr_scheduler_type = lr_schedule,\n",
        "    eval_strategy = \"steps\",\n",
        "    eval_steps = 5,\n",
        "    report_to = report_to,\n",
        "    metric_for_best_model = \"wer\",\n",
        "    push_to_hub = True,\n",
        ")"
      ],
      "metadata": {
        "id": "H0nsDom6NpEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    train_dataset = train_ds,\n",
        "    eval_dataset = eval_ds,\n",
        "    data_collator = data_collator,\n",
        "    compute_metrics = compute_metrics,\n",
        "    processing_class = processor.feature_extractor,\n",
        "    args = training_arguments,\n",
        ")"
      ],
      "metadata": {
        "id": "WLIadZV4NpG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Mcb1BiI7N6Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kwargs = {\n",
        "    \"dataset_tags\": \"huuuyeah/meetingbank\",\n",
        "    \"dataset\": \"huuuyeah/meetingbank\",\n",
        "    \"language\": \"en\",\n",
        "    \"model_name\": \"gemma-3-4b-it_QLoRa\",\n",
        "    \"finetuned_from\": \"google/gemma-3-4b-it\",\n",
        "    \"tasks\": \"text-generation\",\n",
        "}"
      ],
      "metadata": {
        "id": "Wn_tMzn5N6OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(**kwargs)"
      ],
      "metadata": {
        "id": "rKKpjUc2N6Q9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}